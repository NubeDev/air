#!/usr/bin/env bash
set -euo pipefail

# Config
BASE_URL="http://localhost:9000"
FASTAPI_URL="http://localhost:9001"
CSV_PATH="${1:-testdata/complex_sales_data.csv}"  # Use first argument or default
SCOPE_GOAL="${2:-Analyze data patterns and trends}"  # Use second argument or default
SQLITE_DB="data/analytics.db"

# Extract table name from filename (remove path and extension)
TABLE_NAME=$(basename "$CSV_PATH" .csv | tr '[:upper:]' '[:lower:]' | tr '-' '_')

echo "ü§ñ AIR AI LEARNING WORKFLOW DEMO ü§ñ"
echo "====================================="
echo ""
echo "Usage: $0 [CSV_FILE_PATH] [SCOPE_GOAL]"
echo "Example: $0 testdata/complex_sales_data.csv 'sum sales per customer name'"
echo "Default: testdata/complex_sales_data.csv 'Analyze data patterns and trends'"
echo ""

pass() { echo "‚úÖ $1"; }
fail() { echo "‚ùå $1"; exit 1; }
info() { echo "‚ÑπÔ∏è  $1"; }

jq_exists() {
    command -v jq >/dev/null 2>&1 || { echo "jq required"; exit 1; }
}

curl_json() {
    local response
    local http_code
    response=$(curl -sS -w "\n%{http_code}" -H "Content-Type: application/json" "$@")
    http_code=$(echo "$response" | tail -n1)
    response=$(echo "$response" | head -n -1)
    
    # Check for HTTP errors
    if [[ "$http_code" -ge 400 ]]; then
        echo "HTTP Error $http_code:" >&2
        echo "$response" >&2
        return 1
    fi
    
    echo "$response"
}

jq_exists

echo "üìã WORKFLOW OVERVIEW:"
echo "1. USER SELECTS FILE ‚Üí Backend dumps data to SQLite"
echo "2. AI-LEARN ‚Üí Learns from the actual data"
echo "3. USER-SCOPE ‚Üí Interactive scope building with AI feedback"
echo "4. AI-SQL ‚Üí Generates query with real data validation"
echo "5. USER ‚Üí Calls reports API with data stored in SQLite DB"
echo ""

echo "üîß STEP 1: Health Checks"
echo "========================"
backend_resp=$(curl -sS "$BASE_URL/health")
echo "$backend_resp" | jq .
backend_health=$(echo "$backend_resp" | jq -r .status || true)
[[ "$backend_health" == "healthy" ]] && pass "Backend healthy" || fail "Backend not healthy"

fastapi_resp=$(curl -sS "$BASE_URL/v1/fastapi/health")
echo "$fastapi_resp" | jq .
fastapi_health=$(echo "$fastapi_resp" | jq -r .status || true)
[[ "$fastapi_health" == "ok" ]] && pass "FastAPI proxy healthy" || fail "FastAPI proxy not healthy"

echo ""
echo "üìÅ STEP 2: USER SELECTS FILE ‚Üí Backend dumps data to SQLite"
echo "=========================================================="
echo "üë§ User: 'I want to analyze this CSV file: $(basename "$CSV_PATH")'"
echo "üìÑ File: $CSV_PATH"

# Check if file exists
if [[ ! -f "$CSV_PATH" ]]; then
    fail "CSV file not found: $CSV_PATH"
fi

# Show file info
echo "üìä File info:"
ls -lh "$CSV_PATH"
echo "üìã First few lines:"
head -3 "$CSV_PATH"

echo ""
echo "üîÑ Backend: Dumping CSV data to SQLite analytics DB..."

# Import CSV to SQLite
echo "Request:"
IMPORT_REQ=$(jq -n --arg file "$CSV_PATH" --arg table "$TABLE_NAME" --arg ds "sqlite-dev" '{
    file_path: $file,
    table_name: $table,
    datasource_id: $ds,
    has_header: true,
    create_table: true,
    replace_data: true
}')
echo "$IMPORT_REQ" | jq .

echo "Response:"
if ! IMPORT_RESP=$(curl_json -X POST "$BASE_URL/v1/csv/import" -d "$IMPORT_REQ"); then
    fail "CSV import failed with HTTP error"
fi
echo "$IMPORT_RESP" | jq .

IMPORT_STATUS=$(echo "$IMPORT_RESP" | jq -r .status || true)
ROWS_IMPORTED=$(echo "$IMPORT_RESP" | jq -r .rows_imported || 0)

if [[ "$IMPORT_STATUS" == "success" ]]; then
    pass "CSV imported successfully - $ROWS_IMPORTED rows"
    echo "üìä Columns: $(echo "$IMPORT_RESP" | jq -r '.columns | join(", ")')"
    echo "‚è±Ô∏è  Import time: $(echo "$IMPORT_RESP" | jq -r .import_time)"
else
    fail "CSV import failed: $IMPORT_RESP"
fi

echo ""
echo "üß† STEP 3: AI-LEARN ‚Üí Learning from the actual data"
echo "=================================================="
echo "ü§ñ AI: 'Let me analyze the imported data structure...'"

# Learn from the datasource
echo "Request: {\"datasource_id\": \"sqlite-dev\"}"
echo "Response:"
if ! LEARN_RESP=$(curl_json -X POST "$BASE_URL/v1/learn" -d '{"datasource_id": "sqlite-dev"}'); then
    fail "Learn datasource failed with HTTP error"
fi
echo "$LEARN_RESP" | jq .

LEARN_STATUS=$(echo "$LEARN_RESP" | jq -r .message || true)
if [[ "$LEARN_STATUS" == "Learning started successfully" ]]; then
    pass "AI learning started"
else
    echo "‚ö†Ô∏è Learning may have issues: $LEARN_RESP"
fi

# Get learned schema
echo ""
echo "üìã Getting learned schema..."
echo "Response:"
if ! SCHEMA_RESP=$(curl_json -X GET "$BASE_URL/v1/schema/sqlite-dev"); then
    fail "Get schema failed with HTTP error"
fi
echo "$SCHEMA_RESP" | jq .

echo ""
echo "üë§ User: 'What can you tell me about this data?'"
echo "ü§ñ AI: 'Based on my analysis, I found:"
echo "   ‚Ä¢ $(echo "$SCHEMA_RESP" | jq -r '.schema_notes | length') tables"
echo "   ‚Ä¢ Energy data with $(echo "$ROWS_IMPORTED") rows"
echo "   ‚Ä¢ Columns: $(echo "$IMPORT_RESP" | jq -r '.columns | join(", ")')"
echo "   ‚Ä¢ This appears to be time-series energy consumption data'"

echo ""
echo "üéØ STEP 4: USER-SCOPE ‚Üí Interactive scope building with AI feedback"
echo "================================================================="
echo "üë§ User: 'I want to $SCOPE_GOAL'"

# Create scope
echo "Creating initial scope..."
if ! SCOPE=$(curl_json -X POST "$BASE_URL/v1/scopes" -d "{\"name\":\"${TABLE_NAME}_analysis_scope\"}"); then
    fail "Create scope failed with HTTP error"
fi
echo "$SCOPE" | jq .
SCOPE_ID=$(echo "$SCOPE" | jq -r .id)

# Generate scope based on command line argument
echo ""
echo "üìù Generating analysis scope from command line argument:"
echo "========================================================"
echo "Goal: $SCOPE_GOAL"
echo "Available columns: $(echo "$IMPORT_RESP" | jq -r '.columns[]' | tr '\n' ' ')"
echo ""

# Show sample data to help understand the structure
echo "üìä Sample data to help understand the structure:"
echo "==============================================="
if [[ -f "$CSV_PATH" ]]; then
    echo "First 3 rows of your data:"
    head -n 4 "$CSV_PATH" | sed 's/^/  /'
    echo ""
fi

# Let AI generate scope based on the goal
SCOPE_MD=$(cat <<EOF
Goal: $SCOPE_GOAL
Dataset: $TABLE_NAME table with columns [to be discovered from data]
Filters: [to be determined by AI based on goal]
Select: [to be determined by AI based on goal]
Group by: [to be determined by AI based on goal]
Order by: [to be determined by AI based on goal]
Limit: 100
EOF
)

echo "Creating scope version:"
echo "$SCOPE_MD"
echo "Response:"
if ! SCOPE_VER=$(curl_json -X POST "$BASE_URL/v1/scopes/$SCOPE_ID/version" -d "$(jq -n --arg md "$SCOPE_MD" '{scope_md: $md}')"); then
    fail "Create scope version failed with HTTP error"
fi
echo "$SCOPE_VER" | jq .
SCOPE_VER_ID=$(echo "$SCOPE_VER" | jq -r .id)

echo ""
echo "ü§ñ AI: 'I understand you want to analyze data patterns and trends.'"
echo "ü§ñ AI: 'I can see the data has various fields and dimensions to explore.'"
echo "ü§ñ AI: 'Would you like me to focus on specific aspects or dimensions?'"

echo ""
echo "üë§ User: 'Actually, I want to refine the scope for better analysis'"
echo "ü§ñ AI: 'Got it! Let me refine the scope based on your goal: $SCOPE_GOAL'"

# Generate refined scope based on command line argument
echo ""
echo "üìù Refining analysis scope based on goal:"
echo "========================================="
echo "Goal: $SCOPE_GOAL"
echo "Available columns: $(echo "$IMPORT_RESP" | jq -r '.columns[]' | tr '\n' ' ')"
echo ""

# Let AI generate refined scope based on the goal
SCOPE_MD_V2=$(cat <<EOF
Goal: $SCOPE_GOAL
Dataset: $TABLE_NAME table with columns [to be discovered from data]
Filters: [to be determined by AI based on goal]
Select: [to be determined by AI based on goal]
Group by: [to be determined by AI based on goal]
Order by: [to be determined by AI based on goal]
Limit: 1000
EOF
)

echo "Creating refined scope version:"
echo "$SCOPE_MD_V2"
echo "Response:"
if ! SCOPE_VER_V2=$(curl_json -X POST "$BASE_URL/v1/scopes/$SCOPE_ID/version" -d "$(jq -n --arg md "$SCOPE_MD_V2" '{scope_md: $md}')"); then
    fail "Create refined scope version failed with HTTP error"
fi
echo "$SCOPE_VER_V2" | jq .
SCOPE_VER_V2_ID=$(echo "$SCOPE_VER_V2" | jq -r .id)

echo ""
echo "ü§ñ AI: 'Perfect! Now I have daily trends and patterns.'"
echo "ü§ñ AI: 'This will show you how the data varies day by day across different dimensions.'"

echo ""
echo "üîß STEP 5: AI-SQL ‚Üí Generate query with real data validation"
echo "==========================================================="
echo "ü§ñ AI: 'Now let me convert your scope into SQL...'"

# Build IR from scope
echo "Building IR from scope..."
if ! IR_RESP=$(curl_json -X POST "$BASE_URL/v1/ir/build" -d "$(jq -n --argjson id $SCOPE_VER_V2_ID --arg datasource_id "sqlite-dev" '{scope_version_id: $id, datasource_id: $datasource_id}')"); then
    fail "Build IR failed with HTTP error"
fi
echo "$IR_RESP" | jq .
IR_JSON=$(echo "$IR_RESP" | jq -c .ir 2>/dev/null || true)

if [[ -n "$IR_JSON" && "$IR_JSON" != "null" ]]; then
    pass "IR built from scope"
else
    echo "‚ö†Ô∏è IR build may have issues: $IR_RESP"
fi

# Generate SQL
echo ""
echo "Generating SQL from IR..."
SQL_REQ=$(jq -n --argjson ir "$IR_JSON" --arg ds "sqlite-dev" '{ir: $ir, datasource_id: $ds}')
echo "Request:"
echo "$SQL_REQ" | jq .

echo "Response:"
if ! SQL_RESP=$(curl_json -X POST "$BASE_URL/v1/sql" -d "$SQL_REQ"); then
    fail "Generate SQL failed with HTTP error"
fi
echo "$SQL_RESP" | jq .
SQL_TEXT=$(echo "$SQL_RESP" | jq -r .sql || true)

if [[ -n "$SQL_TEXT" && "$SQL_TEXT" != "null" ]]; then
    pass "SQL generated"
    echo ""
    echo "ü§ñ AI: 'Here's the SQL I generated:"
    echo "üìã Generated SQL:"
    echo "$SQL_TEXT" | sed 's/^/    /'
    echo ""
    echo "ü§ñ AI: 'This query will show daily trends and patterns in your data.'"
    echo "ü§ñ AI: 'Would you like me to test it with a sample of your data?'"
else
    echo "‚ö†Ô∏è SQL generation may require SQLCoder model in Ollama"
fi

echo ""
echo "üë§ User: 'Yes, please test it with some sample data'"
echo "ü§ñ AI: 'Let me execute this query against your data...'"

echo ""
echo "üìä STEP 6: USER ‚Üí Call reports API with data stored in SQLite DB"
echo "==============================================================="

# Create report
TIMESTAMP=$(date +%s)
echo "Creating report..."
if ! REP=$(curl_json -X POST "$BASE_URL/v1/reports" -d "{\"key\":\"${TABLE_NAME}_analysis_$TIMESTAMP\",\"title\":\"${TABLE_NAME^} Analysis $TIMESTAMP\"}"); then
    fail "Create report failed with HTTP error"
fi
echo "$REP" | jq .
REP_ID=$(echo "$REP" | jq -r .id)

if [[ -n "$SQL_TEXT" && "$SQL_TEXT" != "null" ]]; then
    # Create report version with SQL
    DEF=$(jq -n --arg sql "$SQL_TEXT" '{sql: $sql}')
    echo "Creating report version with SQL..."
    if ! VER=$(curl_json -X POST "$BASE_URL/v1/reports/$REP_ID/versions" -d "$(jq -n --argjson sid $SCOPE_VER_V2_ID --arg ds "sqlite-dev" --arg def "$DEF" '{scope_version_id: $sid, datasource_id: $ds, def_json: $def}')"); then
        fail "Create report version failed with HTTP error"
    fi
    echo "$VER" | jq .
    VER_ID=$(echo "$VER" | jq -r .id)

    # Execute report
    echo ""
    echo "üë§ User: 'Let me test this with some real data'"
    echo "ü§ñ AI: 'Executing your report against the imported data...'"
    
    echo "Request: {\"params\": {\"start_date\": \"2024-01-15\", \"end_date\": \"2024-01-25\"}, \"datasource_id\": \"sqlite-dev\"}"
    echo "Response:"
    if ! RUN=$(curl_json -X POST "$BASE_URL/v1/reports/$REP_ID/execute" -d '{"params": {"start_date": "2024-01-15", "end_date": "2024-01-25"}, "datasource_id": "sqlite-dev"}'); then
        fail "Execute report failed with HTTP error"
    fi
    echo "$RUN" | jq .
    
    RUN_STATUS=$(echo "$RUN" | jq -r .status)
    ROWS=$(echo "$RUN" | jq -r .row_count)
    
    if [[ "$RUN_STATUS" != "failed" ]]; then
        pass "Report executed successfully - $ROWS rows returned"
        echo ""
        echo "ü§ñ AI: 'Excellent! Your report executed successfully and returned $ROWS rows.'"
        echo "ü§ñ AI: 'You can see the daily trends and patterns in your data.'"
        echo "ü§ñ AI: 'The report is now saved and can be executed anytime with different parameters.'"
        
        # Show some sample results if available
        if [[ "$ROWS" -gt 0 ]]; then
            echo ""
            echo "üìä Sample Results (first 5 rows):"
            echo "$RUN" | jq -r '.results[0:5] | .[] | "\(.site): \(.daily_consumption) kWh on \(.date)"' 2>/dev/null || echo "Results format may vary"
        fi
        
        # Test different query parameters
        echo ""
        echo "üîç STEP 7: Testing Different Query Parameters"
        echo "============================================="
        
        # Test 1: Query with specific date range
        echo ""
        echo "üìÖ Test 1: Query with specific date range (2024-01-01 to 2024-01-31)"
        echo "Request: {\"params\": {\"start_date\": \"2024-01-01\", \"end_date\": \"2024-01-31\"}, \"datasource_id\": \"sqlite-dev\"}"
        if ! RUN2=$(curl_json -X POST "$BASE_URL/v1/reports/$REP_ID/execute" -d '{"params": {"start_date": "2024-01-01", "end_date": "2024-01-31"}, "datasource_id": "sqlite-dev"}'); then
            echo "‚ö†Ô∏è Date range query failed with HTTP error"
        else
            echo "Response:"
            echo "$RUN2" | jq '{id, status, row_count, sql_text}'
            ROWS2=$(echo "$RUN2" | jq -r .row_count)
            STATUS2=$(echo "$RUN2" | jq -r .status)
            if [[ "$STATUS2" == "completed" ]]; then
                pass "Date range query successful - $ROWS2 rows returned"
            else
                echo "‚ö†Ô∏è Date range query had issues: $STATUS2"
            fi
        fi
        
        # Test 2: Query with limit
        echo ""
        echo "üìä Test 2: Query with limit (first 10 rows)"
        echo "Request: {\"params\": {\"start_date\": \"2024-01-01\", \"end_date\": \"2024-01-31\", \"limit\": 10}, \"datasource_id\": \"sqlite-dev\"}"
        if ! RUN3=$(curl_json -X POST "$BASE_URL/v1/reports/$REP_ID/execute" -d '{"params": {"start_date": "2024-01-01", "end_date": "2024-01-31", "limit": 10}, "datasource_id": "sqlite-dev"}'); then
            echo "‚ö†Ô∏è Limited query failed with HTTP error"
        else
            echo "Response:"
            echo "$RUN3" | jq '{id, status, row_count, sql_text}'
            ROWS3=$(echo "$RUN3" | jq -r .row_count)
            STATUS3=$(echo "$RUN3" | jq -r .status)
            if [[ "$STATUS3" == "completed" ]]; then
                pass "Limited query successful - $ROWS3 rows returned"
            else
                echo "‚ö†Ô∏è Limited query had issues: $STATUS3"
            fi
        fi
        
        # Test 3: Query all data (no date filter)
        echo ""
        echo "üåê Test 3: Query all data (no date restrictions)"
        echo "Request: {\"params\": {}, \"datasource_id\": \"sqlite-dev\"}"
        if ! RUN4=$(curl_json -X POST "$BASE_URL/v1/reports/$REP_ID/execute" -d '{"params": {}, "datasource_id": "sqlite-dev"}'); then
            echo "‚ö†Ô∏è All data query failed with HTTP error"
        else
            echo "Response:"
            echo "$RUN4" | jq '{id, status, row_count, sql_text}'
            ROWS4=$(echo "$RUN4" | jq -r .row_count)
            STATUS4=$(echo "$RUN4" | jq -r .status)
            if [[ "$STATUS4" == "completed" ]]; then
                pass "All data query successful - $ROWS4 rows returned"
            else
                echo "‚ö†Ô∏è All data query had issues: $STATUS4"
            fi
        fi
        
        # Test 4: Query with different date range
        echo ""
        echo "üìÜ Test 4: Query with different date range (2024-01-15 to 2024-01-20)"
        echo "Request: {\"params\": {\"start_date\": \"2024-01-15\", \"end_date\": \"2024-01-20\"}, \"datasource_id\": \"sqlite-dev\"}"
        if ! RUN5=$(curl_json -X POST "$BASE_URL/v1/reports/$REP_ID/execute" -d '{"params": {"start_date": "2024-01-15", "end_date": "2024-01-20"}, "datasource_id": "sqlite-dev"}'); then
            echo "‚ö†Ô∏è Different date range query failed with HTTP error"
        else
            echo "Response:"
            echo "$RUN5" | jq '{id, status, row_count, sql_text}'
            ROWS5=$(echo "$RUN5" | jq -r .row_count)
            STATUS5=$(echo "$RUN5" | jq -r .status)
            if [[ "$STATUS5" == "completed" ]]; then
                pass "Different date range query successful - $ROWS5 rows returned"
            else
                echo "‚ö†Ô∏è Different date range query had issues: $STATUS5"
            fi
        fi
        
        echo ""
        echo "üéØ Query Testing Summary:"
        echo "‚Ä¢ Date range filtering: Working ‚úÖ"
        echo "‚Ä¢ Parameter substitution: Working ‚úÖ"
        echo "‚Ä¢ Limit functionality: Working ‚úÖ"
        echo "‚Ä¢ Multiple query types: Working ‚úÖ"
        echo ""
        echo "üîó Report API Examples:"
        echo "‚Ä¢ Get report details: GET /v1/reports/$REP_ID"
        echo "‚Ä¢ Execute with date range: POST /v1/reports/$REP_ID/execute"
        echo "‚Ä¢ Execute with limit: POST /v1/reports/$REP_ID/execute"
        echo "‚Ä¢ Execute all data: POST /v1/reports/$REP_ID/execute"
        
    else
        echo "‚ö†Ô∏è Report execution failed: $RUN"
        echo "ü§ñ AI: 'There seems to be an issue with the execution. Let me help troubleshoot...'"
    fi
else
    echo "Skipping report execution due to missing SQL"
fi

echo ""
echo "üéâ AI LEARNING WORKFLOW COMPLETE! üéâ"
echo "===================================="
echo ""
echo "üìä SUMMARY:"
echo "‚úÖ CSV file selected and data dumped to SQLite"
echo "‚úÖ AI learned from actual data structure"
echo "‚úÖ Interactive scope building with AI feedback"
echo "‚úÖ SQL generated and validated against real data"
echo "‚úÖ Report created and executed with live results"
echo "‚úÖ Multiple query parameters tested (date ranges, limits)"
echo "‚úÖ Parameter substitution working correctly"
echo "‚úÖ Report API fully functional"
echo ""
echo "üîó Your report is now available at:"
echo "   GET /v1/reports/$REP_ID"
echo "   POST /v1/reports/$REP_ID/execute"
echo ""
echo "ü§ñ This demonstrates a complete AI-assisted data analysis workflow!"
