# AIR Implementation Plan - Database + File Processing

## ğŸ¯ Architecture Overview

AIR supports dual processing paths for both database and file-based data analysis.

- DB execution is done in Go against registered analytics datasources (SQLite, Postgres, MySQL, Timescale).
- File reads and ad-hoc file processing are done in Python FastAPI (no ingestion by default).
- Scope generation/refinement uses Llama/ChatGPT; SQL generation uses SQLCoder only.

## ğŸš¦ Phase 0: Datasource Registration (SQLite + PG + MySQL + Files)
- Register analytics datasources via Go using `/v1/datasources` and `internal/datasource` registry:
  - SQLite: `dsn: "file:/data/analytics.db?_fk=1"`
  - Postgres: `dsn: "postgres://user:pass@host:5432/db?sslmode=disable"`
  - MySQL: `dsn: "user:pass@tcp(host:3306)/db"`
  - Files: `base_path: "/data/files"`
- Ensure separate SQLite analytics DB (not `air.db`).

## ğŸš€ Implementation Tasks

### Phase 1: Complete Database Workflow (HIGH)

#### 1.1 Reports Service (`internal/services/reports_service.go`)
- [ ] `CreateScope(req CreateScopeRequest) (*Scope, error)`
- [ ] `GetScope(id uint) (*Scope, error)`
- [ ] `CreateScopeVersion(scopeID uint, req CreateScopeVersionRequest) (*ScopeVersion, error)`
- [ ] `CreateReport(req CreateReportRequest) (*Report, error)`
- [ ] `GetReport(key string) (*Report, error)`
- [ ] `CreateReportVersion(reportKey string, req CreateReportVersionRequest) (*ReportVersion, error)`
- [ ] `RunReport(reportKey string, req RunReportRequest) (*ReportRun, error)`
- [ ] `ExportReport(reportKey string, format string) ([]byte, error)`

#### 1.2 AI Service (DB) (`internal/services/ai_service.go`)
- [ ] `BuildIR(req BuildIRRequest)` â†’ use Llama/ChatGPT to turn scope markdown into IR JSON
- [ ] `GenerateSQLFromIR(req GenerateSQLRequest)` â†’ SQLCoder only; no heuristic fallback
- [ ] `AnalyzeRun(runID, req)` â†’ use Llama/ChatGPT to analyze execution results

#### 1.3 Datasource Learning (`internal/services/datasource_service.go`)
- [ ] `LearnDatasource(req)` â†’ learn schema from DB; store `SchemaNote`
- [ ] `GetSchema(datasourceID)` â†’ return learned schema

### Phase 2: Complete File Learning Workflow (HIGH)

- File reads stay in Python. No ingestion into DB unless explicitly requested later.

#### 2.1 Session Learning Endpoints (`cmd/api/handlers/sessions/`)
- [ ] `POST /v1/sessions/{id}/ask` â†’ Llama/ChatGPT Q&A
- [ ] `POST /v1/sessions/{id}/scope/build` â†’ Draft scope (LLM)
- [ ] `POST /v1/sessions/{id}/scope/refine` â†’ Refine scope (LLM)
- [ ] `POST /v1/sessions/{id}/query/generate` â†’ Build file query plan (LLM-assisted IRâ†’plan)
- [ ] `POST /v1/sessions/{id}/execute` â†’ Call Python to execute plan
- [ ] `POST /v1/sessions/{id}/analyze` â†’ LLM analysis on results
- [ ] `POST /v1/sessions/{id}/save` â†’ Save as GeneratedReport

#### 2.2 Session Service (`internal/services/session_service.go`)
- [ ] `AskQuestion`, `BuildScope`, `RefineScope`
- [ ] `GenerateQuery`, `ExecuteAnalysis`, `AnalyzeResults`, `SaveAsAPI`

#### 2.3 FastAPI Integration (`internal/services/fastapi_client.go`)
- [ ] `LearnFile` (infer schema, profiling)
- [ ] `ExecuteFileQuery` (run query plan)
- [ ] `AnalyzeFileResults`

### Phase 3: Unified Learning Pattern (MEDIUM)
- [ ] `learning_service.go` unifies DB/file learning
- [ ] `scope_builder.go` centralizes scopeâ†’IR (LLM)
- [ ] `query_generator.go` centralizes IRâ†’SQL (SQLCoder) or IRâ†’plan (files)

### Phase 4: UI Integration (MEDIUM)
- [ ] `GET /v1/generated/reports/{id}/schema` (JSON Schema for forms)
- [ ] `GET /v1/reports/{id}/schema`
- [ ] Convert OpenAPI â†’ JSON Schema; client-side validation and hints

## ğŸ“ File Structure (Keep Current Layout)

```
cmd/api/
â”œâ”€â”€ handlers/
â”‚   â”œâ”€â”€ ai/           # AI tools, chat, SQL generation
â”‚   â”œâ”€â”€ db/           # Database datasource management
â”‚   â”œâ”€â”€ fastapi/      # Python FastAPI integration
â”‚   â”œâ”€â”€ generated_reports/  # File-based generated reports
â”‚   â”œâ”€â”€ health/       # Health checks
â”‚   â”œâ”€â”€ reports/      # Database reports and scopes
â”‚   â”œâ”€â”€ sessions/     # File-based learning sessions
â”‚   â””â”€â”€ websocket/    # WebSocket handlers
â”œâ”€â”€ middleware/       # Auth, logging middleware
â”œâ”€â”€ routes/          # Route definitions
â”œâ”€â”€ main.go
â””â”€â”€ server.go

internal/
â”œâ”€â”€ auth/            # JWT authentication
â”œâ”€â”€ config/          # Configuration management
â”œâ”€â”€ datasource/      # Database connectors
â”œâ”€â”€ llm/            # Ollama AI client
â”œâ”€â”€ logger/         # Logging
â”œâ”€â”€ redis/          # Redis client
â”œâ”€â”€ services/       # Business logic services
â”œâ”€â”€ store/          # Database models
â””â”€â”€ websocket/      # WebSocket hub

dataserver/         # Python FastAPI backend (DON'T CHANGE)
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/        # API endpoints
â”‚   â”œâ”€â”€ core/       # Configuration
â”‚   â”œâ”€â”€ models/     # Pydantic models
â”‚   â””â”€â”€ services/   # Data processing
â””â”€â”€ requirements.txt
```

## âœ… Success Criteria

### Database Processing
- [ ] Datasources registered (SQLite, Postgres, MySQL, Files)
- [ ] Scope â†’ IR (LLM)
- [ ] IR â†’ SQL (SQLCoder)
- [ ] SQL executes on selected datasource via Go
- [ ] Reports saved and executed with parameters

### File Processing
- [ ] Sessions over files
- [ ] Scope/IR via LLM
- [ ] Plan executed by Python
- [ ] Generated APIs saved/executed

### Unified
- [ ] Same 8-step workflow for DB and files
- [ ] No heuristic data; outputs from models or real execution only

## Notes
- Go executes SQL only on registered DBs.
- Python handles file reads and execution for adâ€‘hoc file analysis.
- No heuristic SQL fallback; errors bubble up to client with guidance.

Last Updated: 2025-09-30
Status: Planning Phase
Priority: Implement Phase 0â€“2 first
